{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "from google.protobuf.json_format import Parse\n",
    "sys.path.insert(0, 'compiled_protobufs')\n",
    "from taskmap_pb2 import TaskMap\n",
    "from pyserini.search import LuceneSearcher\n",
    "import csv\n",
    "from pprint import pprint\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "searcher_config = {\n",
    "    'BM25': {'b': 0.4, 'k1': 0.9},\n",
    "    # 'BM25+RM3':{\n",
    "    #     'BM25': {'b': 0.4, 'k1': 0.9},\n",
    "    #     'RM3': {'fb_terms': 10, 'fb_docs': 10, 'original_query_weight': 0.5},\n",
    "    # }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "taskmap_cooking_index_path = os.path.join(os.getcwd(), \"indexes\", \"food\", \"system_index_sparse\")\n",
    "\n",
    "def get_pyserini_docs(searcher, query, k, query_id):\n",
    "    \"\"\" Print pyserini results based on specific query, searcher, and k. \"\"\"\n",
    "    results = []\n",
    "    for hit in searcher.search(q=query, k=k):\n",
    "        doc_string = hit.raw\n",
    "        doc_json = json.loads(doc_string)\n",
    "        taskmap_json = doc_json['recipe_document_json']\n",
    "        taskmap = Parse(json.dumps(taskmap_json), TaskMap())\n",
    "        result = {\n",
    "            \"doc-id\" : taskmap.taskmap_id, \n",
    "            \"doc-title\" : taskmap.title, \n",
    "            \"doc-url\" : taskmap.source_url, \n",
    "            \"score\": round(float(hit.score),3),\n",
    "            \"query-id\": query_id,\n",
    "            \"query\": query,\n",
    "            \"taskgraph\" : taskmap,\n",
    "        }\n",
    "        results.append(result)\n",
    "    return results\n",
    "\n",
    "def get_dict_keys_list(judgments, fieldnames):\n",
    "    new_list = []\n",
    "    for judgment in judgments:\n",
    "        dict_item = {}\n",
    "        for key in fieldnames:\n",
    "            dict_item[key] = judgment[key]\n",
    "        new_list.append(dict_item)\n",
    "    return new_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations_path = os.path.join(os.getcwd(), \"datasets\", \"judgments\", \"cooking-annotations2.csv\")\n",
    "annotation_pairs = os.path.join(os.getcwd(), \"datasets\", \"judgments\", \"annotation-pairs.csv\")\n",
    "\n",
    "queries_path = os.path.join(os.getcwd(), \"datasets\", \"queries\", \"cooking_queries.csv\")\n",
    "cooking_queries = pd.read_csv(queries_path).iloc[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "searcher = LuceneSearcher(index_dir=taskmap_cooking_index_path)\n",
    "searcher.set_bm25(b=0.4,k1=0.9)\n",
    "\n",
    "new_judgments = []\n",
    "for idx, query in cooking_queries.iterrows():\n",
    "    new_judgments += get_pyserini_docs(searcher, query[\"target query\"], k=5, query_id=idx)\n",
    "for idx, judgement in enumerate(new_judgments):\n",
    "    judgement[\"judgment-id\"] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['judgment-id', 'query', 'query-id', 'taskgraph']\n"
     ]
    }
   ],
   "source": [
    "# save taskgraph + query pair for analysis\n",
    "with open(annotation_pairs, 'w') as csvfile:\n",
    "    fieldnames = [\"judgment-id\", \"query\", \"query-id\", \"taskgraph\"]\n",
    "    print(fieldnames)\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(get_dict_keys_list(new_judgments, fieldnames))\n",
    "\n",
    "# save annotations values\n",
    "with open(annotations_path, 'w') as csvfile:\n",
    "    fieldnames = ['judgment-id', 'doc-id', \"query-id\", \"relevance\", \"justification\"]\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(get_dict_keys_list(new_judgments, fieldnames[:-2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TurkEmptyJudgmentParser:    \n",
    "    def parse_taskgraph(self, judgment):\n",
    "        taskgraph = judgment[\"taskgraph\"]\n",
    "        taskgraph_steps = [step.response.screen.paragraphs[0] for step in taskgraph.steps]\n",
    "        taskgraph_requirements = [requirements.name for requirements in taskgraph.requirement_list]\n",
    "        taskgraph_title = taskgraph.title\n",
    "        taskgraph_turk_info = {\n",
    "            \"taskgraph title\": taskgraph_title,\n",
    "            \"taskgraph_requirements\": taskgraph_requirements,\n",
    "            \"taskgraph_steps\": taskgraph_steps,\n",
    "        }\n",
    "        return taskgraph_turk_info\n",
    "\n",
    "    def print_taskgraph_info(self, judgment):\n",
    "        turk_info = self.parse_taskgraph(judgment)\n",
    "        judgment_id, query_id, query, doc_id searcher= judgment[\"judgment-id\"], judgment[\"query-id\"], judgment[\"query\"], judgment[\"doc-id\"]\n",
    "        title, requirements, steps = turk_info[\"taskgraph title\"], turk_info[\"taskgraph_requirements\"], turk_info[\"taskgraph_steps\"]\n",
    "        print(\"-\" * 20)\n",
    "        print(f\"Judgment id: {judgment_id}\")\n",
    "        print(f'Query id: {query_id}, Query: {query}')\n",
    "        print(f'Document id: {doc_id}, Title: {title}')\n",
    "        print(f'Requirements: ')\n",
    "        for requirement in requirements:\n",
    "            print(f'  - {requirement}')\n",
    "        print(f'Steps:')\n",
    "        for idx, step in enumerate(steps):\n",
    "            print(f'{idx+1}. {step}')\n",
    "        print(\"-\" * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "Judgment id: 0\n",
      "Query id: 0, Query: risotto without mushrooms\n",
      "Document id: cooking+recipe1m+7c95cd05e17e43fd47582727f015a283, Title: Sausage and Mushroom Risotto\n",
      "Requirements: \n",
      "  - 1 12 cups arborio rice\n",
      "  - 1 tablespoon olive oil\n",
      "  - 3 (14 ounce) cans chicken broth, reduced sodium (you may not need all of it)\n",
      "  - 12 lb Italian sausage, casings removed (I use hot variety)\n",
      "  - 12 lb baby bella mushroom, quartered\n",
      "  - 14 onion, minced\n",
      "  - herbs, your choice (I even like plain without, but rosemary, thyme for example are good)\n",
      "  - black pepper\n",
      "  - 12 cup parmesan cheese, grated\n",
      "Steps:\n",
      "1. In a small saucepan simmer broth.\n",
      "2. Use medium pot.\n",
      "3. On medium heat add olive oil to heat; brown meat while breaking up sausage, add onions.\n",
      "4. When about half way done add mushrooms and saute until soft.\n",
      "5. Stir in risotto.\n",
      "6. Add one ladle full of broth.\n",
      "7. Add herbs if using.\n",
      "8. Reduce heat to simmer.\n",
      "9. As risotto absorbs broth continue adding one ladle full at a time while stirring.\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "judgment_parser = TurkEmptyJudgmentParser()\n",
    "judgment_parser.print_taskgraph_info(new_judgments[0])\n",
    "\n",
    "# for judgment in new_judgments:\n",
    "#     judgment_parser.parse_taskgraph(judgment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models_indexes.bm25_model import BM25Model\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2 (default, Feb 28 2021, 17:03:44) \n[GCC 10.2.1 20210110]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5fc5ba0db375a557a527168d68cfbe4f022bc62df7af9d8f86e24130294f8f8e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
