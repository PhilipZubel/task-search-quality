{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, 'compiled_protobufs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Model: COOKING\n",
      "Taskgraphs already converted. Call overwrite=True in convert_to_taskgraphs() to overwrite the preprocessed taskgraphs.\n",
      "Dataset Model: DIY\n",
      "Taskgraphs already converted. Call overwrite=True in convert_to_taskgraphs() to overwrite the preprocessed taskgraphs.\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Generate Taskgraphs from datasets \"\"\"\n",
    "\n",
    "from models_datasets.recipe_1m_model import AbstractModelDataset\n",
    "from models_datasets.recipe_1m_model import Recipe1MModel\n",
    "from models_datasets.wikihow_model import WikihowModel\n",
    "\n",
    "dataset_models = {\n",
    "    \"COOKING\" : Recipe1MModel,\n",
    "    \"DIY\": WikihowModel,\n",
    "}\n",
    "\n",
    "for model_name, model in dataset_models.items():\n",
    "    dataset_model: AbstractModelDataset = model()\n",
    "    print(f\"Dataset Model: {model_name}\")\n",
    "    dataset_model.convert_to_taskgraphs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>raw query</th>\n",
       "      <th>domain</th>\n",
       "      <th>knowledge</th>\n",
       "      <th>reasoning</th>\n",
       "      <th>seasonal</th>\n",
       "      <th>region</th>\n",
       "      <th>target query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>query-0</td>\n",
       "      <td>how to spatchcock a turkey</td>\n",
       "      <td>cooking</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "      <td>usa</td>\n",
       "      <td>spatchcock turkey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>query-1</td>\n",
       "      <td>I want an easy dessert for christmas</td>\n",
       "      <td>cooking</td>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "      <td>-</td>\n",
       "      <td>easi dessert christma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>query-2</td>\n",
       "      <td>Any recommendations for a gluten free appetizer</td>\n",
       "      <td>cooking</td>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>-</td>\n",
       "      <td>gluten free appet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>query-3</td>\n",
       "      <td>how to make a green goddess salad</td>\n",
       "      <td>cooking</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>usa</td>\n",
       "      <td>green goddess salad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>query-4</td>\n",
       "      <td>how to make a classic english trifle</td>\n",
       "      <td>cooking</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "      <td>uk</td>\n",
       "      <td>classic english trifl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                        raw query   domain  \\\n",
       "0  query-0                       how to spatchcock a turkey  cooking   \n",
       "1  query-1             I want an easy dessert for christmas  cooking   \n",
       "2  query-2  Any recommendations for a gluten free appetizer  cooking   \n",
       "3  query-3                how to make a green goddess salad  cooking   \n",
       "4  query-4             how to make a classic english trifle  cooking   \n",
       "\n",
       "  knowledge reasoning seasonal region           target query  \n",
       "0         n         y        y    usa      spatchcock turkey  \n",
       "1         y         y        y      -  easi dessert christma  \n",
       "2         y         y        n      -      gluten free appet  \n",
       "3         y         n        n    usa    green goddess salad  \n",
       "4         n         y        y     uk  classic english trifl  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\"\"\" Preprocess and load queries \"\"\"\n",
    "\n",
    "# from query_pipeline import query_pipeline\n",
    "# query_pipeline.preprocess_queries()\n",
    "\n",
    "queries = {\n",
    "    \"COOKING\" : pd.read_csv('queries/cooking.csv'),\n",
    "    \"DIY\": pd.read_csv('queries/diy.csv'),\n",
    "}\n",
    "\n",
    "queries[\"COOKING\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from models_indexes.marqo_model import MarqoModel\n",
    "# marqo_diy = MarqoModel(domain = \"DIY\")\n",
    "# marqo_diy.build_index()\n",
    "# marqo_diy.search(\"cleaning\")\n",
    "# marqo_diy.search(\"cleaning\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ance dense index already built. Call overwrite=True in build_index() to rebuild the index again.\n",
      "easi dessert christma, https://cookpad.com/us/recipes/346734-amies-margarine-cheesecake\n",
      "easi dessert christma, https://cookpad.com/us/recipes/344168-amies-special-christmas-cake\n",
      "easi dessert christma, http://online-cookbook.com/goto/cook/rpage/0001F3\n",
      "easi dessert christma, https://cookpad.com/us/recipes/346980-amies-cherry-cheesecake\n",
      "easi dessert christma, https://cookpad.com/us/recipes/339392-amies-special-chocolate-cake\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Build indexes from datasets \"\"\"\n",
    "\n",
    "# from models_indexes.bm25_model import BM25Model\n",
    "\n",
    "# bm25_food = BM25Model(domain = \"COOKING\", t5=True)\n",
    "# bm25_food.build_index()\n",
    "\n",
    "# from models_indexes.ance_model import AnceModel\n",
    "# ance_diy: AnceModel = AnceModel(domain = \"DIY\")\n",
    "\n",
    "# bm25_cooking = BM25Model(domain = \"DIY\", t5=True)\n",
    "# bm25_cooking.build_index()\n",
    "\n",
    "# from models_indexes.colbert_model import ColbertModel\n",
    "# colbert_cooking: ColbertModel = ColbertModel(domain = \"COOKING\")\n",
    "# colbert_cooking.build_index()\n",
    "\n",
    "# query = queries[\"COOKING\"][\"target query\"][0]\n",
    "# query = \"pizza\"\n",
    "# colbert_cooking.search(query)\n",
    "# colbert_diy.convert_search_results_to_run()\n",
    "# colbert_diy.create_empty_judgments()\n",
    "\n",
    "# from models_indexes.ance_model import AnceModel\n",
    "# ance: AnceModel = AnceModel(domain = \"COOKING\")\n",
    "# ance.build_index()\n",
    "# ance.search(\"easi dessert christma\")\n",
    "\n",
    "# from models_indexes.colbert_model import ColbertModel\n",
    "# colbert: ColbertModel = ColbertModel(domain = \"COOKING\")\n",
    "# colbert.build_index()\n",
    "# colbert.search(\"pizza\")\n",
    "\n",
    "from models_indexes.colbert_model import ColbertModel\n",
    "colbert: ColbertModel = ColbertModel(domain = \"DIY\")\n",
    "colbert.build_index()\n",
    "colbert.search(\"kitchen\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'numberOfDocuments': 10}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marqo_cooking = MarqoModel(domain = \"COOKING\")\n",
    "marqo_cooking.build_index()\n",
    "marqo_cooking.search(\"fish\")\n",
    "\n",
    "# queries_path = os.path.join(os.getcwd(), \"queries\", \"cooking.csv\")\n",
    "\n",
    "# pd_cooking_queries = pd.read_csv(queries_path).iloc[:10]\n",
    "# bm25_food.convert_search_results_to_run(pd_cooking_queries)\n",
    "# bm25_food.create_empty_judgments(pd_cooking_queries, 5)\n",
    "# queries_path = os.path.join(os.getcwd(), \"queries\", \"diy.csv\")\n",
    "# pd_diy_queries = pd.read_csv(queries_path).iloc[:10]\n",
    "# ance_diy.build_index()\n",
    "# ance_diy.convert_search_results_to_run(pd_diy_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ance dense index already built. Call overwrite=True in build_index() to rebuild the index again.\n"
     ]
    }
   ],
   "source": [
    "# ance_cooking = AnceModel(domain = \"COOKING\")\n",
    "# ance_cooking.build_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-28 19:04:33.540330: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-12-28 19:04:36.119080: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-12-28 19:04:36.119343: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-12-28 19:04:36.119373: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-alexa): /proc/driver/nvidia/version does not exist\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Judgment: granola http://tastykitchen.com/recipes/breakfastbrunch/lavender-yogurt-parfait/\n",
      "Judgment: granola http://tastykitchen.com/recipes/salads/red-berry-salad-with-granola-crusted-goat-cheese/\n",
      "Judgment: granola http://tastykitchen.com/recipes/desserts/maple-pumpkin-tart-with-gingersnap-granola-crust/\n",
      "Judgment: granola http://www.food.com/recipe/granola-gems-134957\n",
      "Judgment: granola http://www.food.com/recipe/pretzel-peanut-butter-granola-395465\n",
      "Judgment: granola http://www.foodandwine.com/recipes/chocolate-peanut-butter-granola-cookies\n",
      "Judgment: granola http://tastykitchen.com/recipes/breakfastbrunch/chocolate-granola/\n",
      "Judgment: granola http://www.food.com/recipe/creamy-pumpkin-parfaits-77650\n",
      "Judgment: granola http://www.food.com/recipe/deep-fried-granola-french-toast-523627\n",
      "Judgment: granola http://tastykitchen.com/recipes/breakfastbrunch/homemade-granola-13/\n"
     ]
    }
   ],
   "source": [
    "# from models_indexes.bm25_model import BM25Model\n",
    "# bm25_cooking = BM25Model(domain = \"COOKING\")\n",
    "# bm25_cooking.build_index()\n",
    "\n",
    "# queries_path = os.path.join(os.getcwd(), \"queries\", \"cooking.csv\")\n",
    "# pd_cooking_queries = pd.read_csv(queries_path).iloc[:10]\n",
    "# query = \"granola\"\n",
    "# bm25_cooking.search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-29 12:37:31.149331: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-12-29 12:37:33.035453: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-12-29 12:37:33.035539: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-12-29 12:37:33.035578: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-alexa): /proc/driver/nvidia/version does not exist\n",
      "/home/philip/task-search-quality/env/lib/python3.9/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving preprocessed cooking dataset\n",
      "Saving preprocessed diy dataset\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5fc5ba0db375a557a527168d68cfbe4f022bc62df7af9d8f86e24130294f8f8e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
