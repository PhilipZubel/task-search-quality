{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, './compiled_protobufs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names = [\"seriouseats\", \"wikihow\"]\n",
    "dataset_paths = [os.path.join(os.getcwd(), \"bin\", dataset,\"taskmap\") for dataset in dataset_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load queries\n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "    \n",
    "# import queries \n",
    "cooking_queries = pd.read_csv('dataset/queries/cooking_queries.csv') \n",
    "diy_queries = pd.read_csv('dataset/queries/diy_queries.csv') \n",
    "print(\"Cooking and DIY queries loaded.\")\n",
    "\n",
    "# split train/test/validation - 80/10/10\n",
    "q_cooking_train, q_rem = train_test_split(cooking_queries, test_size=0.2, random_state=2022)\n",
    "q_cooking_test, q_cooking_validation = train_test_split(q_rem, test_size=0.5, random_state=2022)\n",
    "print(f\"Cooking queries: training set size {len(q_cooking_train)}, test set size {len(q_cooking_test)}, validation set size {len(q_cooking_validation)}\")\n",
    "\n",
    "q_diy_train, q_rem = train_test_split(diy_queries, test_size=0.2, random_state=2022)\n",
    "q_diy_test, q_diy_validation = train_test_split(q_rem, test_size=0.5, random_state=2022)\n",
    "print(f\"DIY queries: training set size {len(q_diy_train)}, test set size {len(q_diy_test)}, validation set size {len(q_diy_validation)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Marqo Index Builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from index_builder.marqo_index_builder import MarqoIndexBuilder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MarqoBuilder = MarqoIndexBuilder()\n",
    "for taskmap_dir, dataset_name in zip(dataset_paths, dataset_names):\n",
    "    MarqoBuilder.build_json_docs(input_dir=taskmap_dir,\n",
    "                                    output_dir=output_temp_dir,\n",
    "                                    dataset_name=dataset_name)\n",
    "    \n",
    "MarqoBuilder.build_index(input_dir=output_temp_dir,\n",
    "                                    output_dir=output_index_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Query index example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = MarqoBuilder.query_index(\"I want pasta\")\n",
    "import pprint\n",
    "pprint.pprint(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Filter usage example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = MarqoBuilder.query_index_filter('I want pasta.', 'Domain:(wikihow)')\n",
    "import pprint\n",
    "pprint.pprint(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relevance judgements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import jsonlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\n",
    "    \"I want pizza pepperoni.\",\n",
    "    \"I would like to make spaghetti bolognese.\",\n",
    "    \"I want to prepare smoked salmon.\"\n",
    "]     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get rank and score from the marqo index and save these in a run file\n",
    "\n",
    "run = []\n",
    "for queryid, query in enumerate(queries):\n",
    "    results = MarqoBuilder.query_index(query)\n",
    "    for rank, doc in enumerate(results[\"hits\"]):\n",
    "        d = {}\n",
    "        d[\"query_id\"] = f'query-{queryid}'\n",
    "        d[\"doc_id\"] = doc[\"_id\"]\n",
    "        d[\"score\"] = doc[\"_score\"]\n",
    "        d[\"rank\"] = rank + 1\n",
    "        run.append(d)\n",
    "\n",
    "# jsonlines.Writer(open('qrels/run.jsonl', 'w')).write_all(run)\n",
    "\n",
    "with open(\"qrels/run.run\", \"w\") as f:\n",
    "    lines = []\n",
    "    for line in run:\n",
    "        lines.append(f'{line[\"query_id\"]} Q0 {line[\"doc_id\"]} {line[\"rank\"]} {line[\"score\"]} t5-maxp\\n')\n",
    "    lines[-1] = lines[-1].replace(\"\\n\",\"\")\n",
    "    f.writelines(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qrel_reader = jsonlines.Reader(open(\"qrels/qrels.jsonl\", \"r\"))\n",
    "# qrels = pd.DataFrame([line for line in qrel_reader])\n",
    "# qrels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IR MEASURES\n",
    "- nDCG - normalized Discounted Cumulative Gain (nDCG) - highly relevant documents appearing lower in a search result list should be penalized as the graded relevance value is reduced logarithmically\n",
    "- precision - fraction of the documents retrieved that are relevant to the user's information need\n",
    "- recall - fraction of the documents that are relevant to the query that are successfully retrieved\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ir_measures\n",
    "from ir_measures import *\n",
    "\n",
    "qrels = ir_measures.read_trec_qrels('qrels/qrels.qrles')\n",
    "run = ir_measures.read_trec_run('qrels/run.run')\n",
    "\n",
    "ir_measures.calc_aggregate([nDCG@3, Precision@3, Recall@3], qrels, run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pyserini Index Builder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from index_builder.pyserini_bm25_builder import PyseriniBM25Builder\n",
    "output_temp_dir = os.path.join(os.getcwd(), \"temp\", \"system_index_sparse\")\n",
    "output_index_dir = os.path.join(os.getcwd(), \"indexes\", \"system_index_sparse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PyseriniBM25Builder = PyseriniBM25Builder()\n",
    "for taskmap_dir, dataset_name in zip(dataset_paths, dataset_names):\n",
    "    PyseriniBM25Builder.build_json_docs(input_dir=taskmap_dir,\n",
    "                                    output_dir=output_temp_dir,\n",
    "                                    dataset_name=dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate index.\n",
    "PyseriniBM25Builder.build_index(input_dir=output_temp_dir,\n",
    "                                    output_dir=output_index_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyserini.search.lucene import LuceneSearcher    \n",
    "import json\n",
    "\n",
    "searcher = LuceneSearcher(index_dir=output_index_dir)\n",
    "\n",
    "last_utterance = \"pasta\"\n",
    "top_k = 5\n",
    "\n",
    "hits = searcher.search(q=last_utterance, k=top_k)\n",
    "\n",
    "docs = []\n",
    "docs_id = []\n",
    "docs_score = []\n",
    "for hit in hits:\n",
    "    doc_id, doc_score = hit.docid, hit.score\n",
    "    doc = searcher.doc(docid=hit.docid)\n",
    "    docs.append(doc.raw())\n",
    "    print(doc_id, doc_score)\n",
    "\n",
    "for doc_string in docs[0:1]:\n",
    "    doc_json = json.loads(doc_string)\n",
    "    taskmap_json = doc_json['recipe_document_json']\n",
    "    # print(taskmap_json)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ance Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from index_builder.pyserini_ance_builder import PyseriniAnceBuilder\n",
    "\n",
    "output_temp_dir_ance = os.path.join(os.getcwd(), \"temp\", \"system_index_ance\")\n",
    "output_index_dir_ance = os.path.join(os.getcwd(), \"indexes\", \"system_index_ance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PyseriniAnce = PyseriniAnceBuilder()\n",
    "for taskmap_dir, dataset_name in zip(dataset_paths, dataset_names):\n",
    "    PyseriniAnce.build_json_docs(input_dir=taskmap_dir,\n",
    "                                    output_dir=output_temp_dir_ance,\n",
    "                                    dataset_name=dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate index.\n",
    "PyseriniAnce.build_index(input_dir=output_temp_dir_ance,\n",
    "                            output_dir=output_index_dir_ance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyserini.search.faiss import FaissSearcher, AnceQueryEncoder\n",
    "encoder = AnceQueryEncoder(\"castorini/ance-msmarco-passage\")\n",
    "searcher = FaissSearcher(\n",
    "    index_dir = output_index_dir_ance,\n",
    "    query_encoder= encoder,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hits = searcher.search(\"pasta\")\n",
    "\n",
    "for i in range(0, 10):\n",
    "    print(f'{i+1:2} {hits[i].docid} {hits[i].score}' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BM25 + MonoT5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-05 15:38:21 [INFO] loader: Loading faiss with AVX2 support.\n",
      "2022-12-05 15:38:21 [INFO] loader: Successfully loaded faiss with AVX2 support.\n",
      "2022-12-05 15:38:23.925567: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2022-12-05 15:38:26.733245: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-12-05 15:38:26.733322: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-12-05 15:38:26.733359: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (instance-alexa): /proc/driver/nvidia/version does not exist\n"
     ]
    }
   ],
   "source": [
    "sys.path.insert(0, './pygaggle')\n",
    "from pygaggle.rerank.base import Query, Text\n",
    "from pygaggle.rerank.transformer import MonoT5\n",
    "\n",
    "reranker =  MonoT5()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = Query('pasta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5fc5ba0db375a557a527168d68cfbe4f022bc62df7af9d8f86e24130294f8f8e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
