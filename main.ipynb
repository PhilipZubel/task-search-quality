{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, 'compiled_protobufs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Model: COOKING\n",
      "Loading taskgraphs...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/ubuntu/task-search-quality/task_datasets/recipe1mln_tasks/layer1.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m dataset_model: AbstractModelDataset \u001b[39m=\u001b[39m model()\n\u001b[1;32m     14\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDataset Model: \u001b[39m\u001b[39m{\u001b[39;00mmodel_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m dataset_model\u001b[39m.\u001b[39;49mconvert_to_taskgraphs()\n",
      "File \u001b[0;32m~/task-search-quality/models_datasets/recipe_1m_model.py:28\u001b[0m, in \u001b[0;36mRecipe1MModel.convert_to_taskgraphs\u001b[0;34m(self, overwrite)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[39m# load taskgraphs\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mLoading taskgraphs...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 28\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m__raw_tasks_file_path) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m     29\u001b[0m     recipe_dataset \u001b[39m=\u001b[39m json\u001b[39m.\u001b[39mload(f)\n\u001b[1;32m     31\u001b[0m \u001b[39m# load convertor and preprocess taskgraphs\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/ubuntu/task-search-quality/task_datasets/recipe1mln_tasks/layer1.json'"
     ]
    }
   ],
   "source": [
    "\"\"\" Generate Taskgraphs from datasets \"\"\"\n",
    "\n",
    "from models_datasets.recipe_1m_model import AbstractModelDataset\n",
    "from models_datasets.recipe_1m_model import Recipe1MModel\n",
    "from models_datasets.wikihow_model import WikihowModel\n",
    "\n",
    "dataset_models = {\n",
    "    \"COOKING\" : Recipe1MModel,\n",
    "    \"DIY\": WikihowModel,\n",
    "}\n",
    "\n",
    "for model_name, model in dataset_models.items():\n",
    "    dataset_model: AbstractModelDataset = model()\n",
    "    print(f\"Dataset Model: {model_name}\")\n",
    "    dataset_model.convert_to_taskgraphs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>raw query</th>\n",
       "      <th>domain</th>\n",
       "      <th>knowledge</th>\n",
       "      <th>complex</th>\n",
       "      <th>many points of view</th>\n",
       "      <th>different key entities</th>\n",
       "      <th>seasonal</th>\n",
       "      <th>regional</th>\n",
       "      <th>target query</th>\n",
       "      <th>short query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>query-0</td>\n",
       "      <td>how to spatchcock a turkey</td>\n",
       "      <td>cooking</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>usa</td>\n",
       "      <td>spatchcock turkey</td>\n",
       "      <td>spatchcock a turkey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>query-1</td>\n",
       "      <td>I want an easy to make dessert for christmas</td>\n",
       "      <td>cooking</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>-</td>\n",
       "      <td>easi dessert christma</td>\n",
       "      <td>easy to make dessert for christmas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>query-2</td>\n",
       "      <td>any recommendations for a gluten free appetizer</td>\n",
       "      <td>cooking</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>-</td>\n",
       "      <td>gluten free appet</td>\n",
       "      <td>gluten free appetizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>query-3</td>\n",
       "      <td>how to make a green goddess salad</td>\n",
       "      <td>cooking</td>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>usa</td>\n",
       "      <td>green goddess salad</td>\n",
       "      <td>green goddess salad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>query-4</td>\n",
       "      <td>how to make a classic english trifle</td>\n",
       "      <td>cooking</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "      <td>uk</td>\n",
       "      <td>classic english trifl</td>\n",
       "      <td>classic english trifle</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                        raw query   domain  \\\n",
       "0  query-0                       how to spatchcock a turkey  cooking   \n",
       "1  query-1     I want an easy to make dessert for christmas  cooking   \n",
       "2  query-2  any recommendations for a gluten free appetizer  cooking   \n",
       "3  query-3                how to make a green goddess salad  cooking   \n",
       "4  query-4             how to make a classic english trifle  cooking   \n",
       "\n",
       "  knowledge complex many points of view different key entities seasonal  \\\n",
       "0         n       y                   n                      n        y   \n",
       "1         n       y                   y                      n        y   \n",
       "2         y       n                   y                      y        n   \n",
       "3         y       y                   n                      y        n   \n",
       "4         y       n                   n                      y        y   \n",
       "\n",
       "  regional           target query                         short query  \n",
       "0      usa      spatchcock turkey                 spatchcock a turkey  \n",
       "1        -  easi dessert christma  easy to make dessert for christmas  \n",
       "2        -      gluten free appet               gluten free appetizer  \n",
       "3      usa    green goddess salad                 green goddess salad  \n",
       "4       uk  classic english trifl              classic english trifle  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\"\"\" Preprocess and load queries \"\"\"\n",
    "\n",
    "# from query_pipeline import query_pipeline\n",
    "# query_pipeline.preprocess_queries()\n",
    "\n",
    "queries = {\n",
    "    \"COOKING\" : pd.read_csv('queries/cooking.csv'),\n",
    "    \"DIY\": pd.read_csv('queries/diy.csv'),\n",
    "}\n",
    "\n",
    "queries[\"COOKING\"].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>raw query</th>\n",
       "      <th>domain</th>\n",
       "      <th>knowledge</th>\n",
       "      <th>complexity</th>\n",
       "      <th>many points of view</th>\n",
       "      <th>multiple key entities</th>\n",
       "      <th>subfield</th>\n",
       "      <th>target query</th>\n",
       "      <th>short query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>query-0</td>\n",
       "      <td>how to choose a good hairstyle for men</td>\n",
       "      <td>diy</td>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>appearance</td>\n",
       "      <td>choos good hairstyl men</td>\n",
       "      <td>choose a good hirstyle for men</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>query-1</td>\n",
       "      <td>how to learn a new language</td>\n",
       "      <td>diy</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>self improvement</td>\n",
       "      <td>learn new languag</td>\n",
       "      <td>learn a new language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>query-2</td>\n",
       "      <td>how to remove food stains from a carpet</td>\n",
       "      <td>diy</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>maintanence</td>\n",
       "      <td>remov food stain carpet</td>\n",
       "      <td>remove food stains from a carpet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>query-3</td>\n",
       "      <td>how to wash a car with less water</td>\n",
       "      <td>diy</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "      <td>maintanence</td>\n",
       "      <td>wash car water</td>\n",
       "      <td>wash a car with less water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>query-4</td>\n",
       "      <td>how do I decorate an office</td>\n",
       "      <td>diy</td>\n",
       "      <td>n</td>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>home improvement</td>\n",
       "      <td>decor offic</td>\n",
       "      <td>decorate an office</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                raw query domain knowledge  \\\n",
       "0  query-0   how to choose a good hairstyle for men    diy         y   \n",
       "1  query-1              how to learn a new language    diy         n   \n",
       "2  query-2  how to remove food stains from a carpet    diy         n   \n",
       "3  query-3        how to wash a car with less water    diy         n   \n",
       "4  query-4              how do I decorate an office    diy         n   \n",
       "\n",
       "  complexity many points of view multiple key entities          subfield  \\\n",
       "0          y                   y                     n        appearance   \n",
       "1          n                   y                     n  self improvement   \n",
       "2          y                   n                     y       maintanence   \n",
       "3          n                   y                     y       maintanence   \n",
       "4          y                   y                     n  home improvement   \n",
       "\n",
       "              target query                       short query  \n",
       "0  choos good hairstyl men    choose a good hirstyle for men  \n",
       "1        learn new languag              learn a new language  \n",
       "2  remov food stain carpet  remove food stains from a carpet  \n",
       "3           wash car water        wash a car with less water  \n",
       "4              decor offic                decorate an office  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries[\"DIY\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/task-search-quality/env/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-02-05 14:06:03.229567: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-05 14:06:04.204029: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-05 14:06:04.204128: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-02-05 14:06:04.204140: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-02-05 14:06:06.131691: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-02-05 14:06:06.131728: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-02-05 14:06:06.131755: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ip-172-31-95-135): /proc/driver/nvidia/version does not exist\n"
     ]
    }
   ],
   "source": [
    "from models_indexes.bm25_model import BM25Model\n",
    "from models_indexes.ance_model import AnceModel\n",
    "from models_indexes.colbert_model import ColbertModel\n",
    "from models_indexes.marqo_model import MarqoModel\n",
    "from models_indexes.abstract_model import AbstractModel\n",
    "\n",
    "models = {}\n",
    "\n",
    "for domain in  [\"COOKING\", \"DIY\"]:\n",
    "# for domain in  [\"COOKING\"]:\n",
    "    models[domain] = {\n",
    "        # \"bm25\" : BM25Model(domain = domain),\n",
    "        # \"bm25+rm3\" : BM25Model(domain = domain, rm3=True),\n",
    "        # \"bm25+t5\" : BM25Model(domain = domain, t5=True),\n",
    "        # \"bm25+rm3+t5\" : BM25Model(domain = domain, rm3=True, t5=True),\n",
    "        \"ance+t5\": AnceModel(domain = domain, t5=True),\n",
    "        \"colbert+t5\": ColbertModel(domain = domain, t5=True),\n",
    "        # \"marqo\": MarqoModel(domain = domain),\n",
    "        # \"marqo\": MarqoModel(domain = domain),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models_indexes.marqo_model import MarqoModel\n",
    "\n",
    "# model = MarqoModel(domain = \"DIY\")\n",
    "# model.build_index()\n",
    "# model.convert_search_results_to_run(pd, raw=False)\n",
    "# model.search(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "path = \"indexes/temp/cooking/system_index_marqo/recipe1m+-taskmaps.json\"\n",
    "# path2 = \"indexes/temp/cooking/system_index_marqo/recipe1m+-taskmaps copy.json\"\n",
    "\n",
    "with open(path, \"r\") as f:\n",
    "    obj = json.load(f)\n",
    "    \n",
    "# with open(path2, \"r\") as f:\n",
    "#     obj2 = json.load(f)\n",
    "\n",
    "print(len(obj))\n",
    "# print(len(obj2))\n",
    "\n",
    "# obj = obj[995500:]\n",
    "\n",
    "# with open(path, 'w') as f:\n",
    "#     f.write(json.dumps(obj, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build indexes\n",
    "print(\"Build indexes\")\n",
    "for domain, index_models in models.items():\n",
    "    for model_name, model in index_models.items():\n",
    "        model.build_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating run files \n",
      "DOMAIN COOKING\n",
      "Run file saved at /home/ubuntu/task-search-quality/measurements/cooking/run_files/ance+t5.run\n",
      "Run file saved at /home/ubuntu/task-search-quality/measurements/cooking/run_files/TCT-ColBERTv2+t5.run\n",
      "DOMAIN DIY\n",
      "Run file saved at /home/ubuntu/task-search-quality/measurements/diy/run_files/ance+t5.run\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDOMAIN \u001b[39m\u001b[39m{\u001b[39;00mdomain\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m model_name, model \u001b[39min\u001b[39;00m index_models\u001b[39m.\u001b[39mitems():\n\u001b[0;32m----> 7\u001b[0m     model\u001b[39m.\u001b[39;49mconvert_search_results_to_run(qs)\n",
      "File \u001b[0;32m~/task-search-quality/models_indexes/colbert_model.py:118\u001b[0m, in \u001b[0;36mColbertModel.convert_search_results_to_run\u001b[0;34m(self, pd_queries)\u001b[0m\n\u001b[1;32m    112\u001b[0m     retrived_hits \u001b[39m=\u001b[39m [lucene_searcher\u001b[39m.\u001b[39mdoc(hit\u001b[39m.\u001b[39mdocid) \u001b[39mfor\u001b[39;00m hit \u001b[39min\u001b[39;00m hits]\n\u001b[1;32m    113\u001b[0m     \u001b[39m# for hit in hits:\u001b[39;00m\n\u001b[1;32m    114\u001b[0m     \u001b[39m#     retrived_hits.append()\u001b[39;00m\n\u001b[1;32m    115\u001b[0m     \u001b[39m# print(type(retrived_hits[0]))\u001b[39;00m\n\u001b[1;32m    116\u001b[0m     \u001b[39m# print(retrived_hits[0])\u001b[39;00m\n\u001b[1;32m    117\u001b[0m     \u001b[39m# print(retrived_hits)\u001b[39;00m\n\u001b[0;32m--> 118\u001b[0m     hits \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreranker\u001b[39m.\u001b[39;49mrerank(Query(query[\u001b[39m\"\u001b[39;49m\u001b[39mtarget query\u001b[39;49m\u001b[39m\"\u001b[39;49m]), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdense_hits_to_text(retrived_hits, scores, ids))\n\u001b[1;32m    119\u001b[0m \u001b[39mfor\u001b[39;00m rank, hit \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(hits[:\u001b[39m50\u001b[39m]):\n\u001b[1;32m    120\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(hit) \u001b[39m==\u001b[39m Text:\n",
      "File \u001b[0;32m~/task-search-quality/./pygaggle/pygaggle/rerank/base.py:72\u001b[0m, in \u001b[0;36mReranker.rerank\u001b[0;34m(self, query, texts)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrerank\u001b[39m(\u001b[39mself\u001b[39m, query: Query, texts: List[Text]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[Text]:\n\u001b[1;32m     70\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Sorts a list of texts\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msorted\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrescore(query, texts), key\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: x\u001b[39m.\u001b[39mscore, reverse\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/task-search-quality/./pygaggle/pygaggle/rerank/transformer.py:113\u001b[0m, in \u001b[0;36mMonoT5.rescore\u001b[0;34m(self, query, texts)\u001b[0m\n\u001b[1;32m    111\u001b[0m input_ids \u001b[39m=\u001b[39m batch\u001b[39m.\u001b[39moutput[\u001b[39m'\u001b[39m\u001b[39minput_ids\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m    112\u001b[0m attn_mask \u001b[39m=\u001b[39m batch\u001b[39m.\u001b[39moutput[\u001b[39m'\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m--> 113\u001b[0m _, batch_scores \u001b[39m=\u001b[39m greedy_decode(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel,\n\u001b[1;32m    114\u001b[0m                                 input_ids,\n\u001b[1;32m    115\u001b[0m                                 length\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m    116\u001b[0m                                 attention_mask\u001b[39m=\u001b[39;49mattn_mask,\n\u001b[1;32m    117\u001b[0m                                 return_last_logits\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    119\u001b[0m batch_scores \u001b[39m=\u001b[39m batch_scores[:, [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtoken_false_id, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtoken_true_id]]\n\u001b[1;32m    120\u001b[0m batch_scores \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mfunctional\u001b[39m.\u001b[39mlog_softmax(batch_scores, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/task-search-quality/env/lib/python3.10/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/task-search-quality/./pygaggle/pygaggle/model/decode.py:20\u001b[0m, in \u001b[0;36mgreedy_decode\u001b[0;34m(model, input_ids, length, attention_mask, return_last_logits)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39m@torch\u001b[39m\u001b[39m.\u001b[39mno_grad()\n\u001b[1;32m     12\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgreedy_decode\u001b[39m(model: PreTrainedModel,\n\u001b[1;32m     13\u001b[0m                   input_ids: torch\u001b[39m.\u001b[39mTensor,\n\u001b[1;32m     14\u001b[0m                   length: \u001b[39mint\u001b[39m,\n\u001b[1;32m     15\u001b[0m                   attention_mask: torch\u001b[39m.\u001b[39mTensor \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     16\u001b[0m                   return_last_logits: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DecodedOutput:\n\u001b[1;32m     17\u001b[0m     decode_ids \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfull((input_ids\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m), \u001b[39m1\u001b[39m),\n\u001b[1;32m     18\u001b[0m                             model\u001b[39m.\u001b[39mconfig\u001b[39m.\u001b[39mdecoder_start_token_id,\n\u001b[1;32m     19\u001b[0m                             dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mlong)\u001b[39m.\u001b[39mto(input_ids\u001b[39m.\u001b[39mdevice)\n\u001b[0;32m---> 20\u001b[0m     encoder_outputs \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mget_encoder()(input_ids, attention_mask\u001b[39m=\u001b[39;49mattention_mask)\n\u001b[1;32m     21\u001b[0m     next_token_logits \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     22\u001b[0m     \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(length):\n",
      "File \u001b[0;32m~/task-search-quality/env/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/task-search-quality/env/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:1052\u001b[0m, in \u001b[0;36mT5Stack.forward\u001b[0;34m(self, input_ids, attention_mask, encoder_hidden_states, encoder_attention_mask, inputs_embeds, head_mask, cross_attn_head_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1039\u001b[0m     layer_outputs \u001b[39m=\u001b[39m checkpoint(\n\u001b[1;32m   1040\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m   1041\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         \u001b[39mNone\u001b[39;00m,  \u001b[39m# past_key_value is always None with gradient checkpointing\u001b[39;00m\n\u001b[1;32m   1050\u001b[0m     )\n\u001b[1;32m   1051\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1052\u001b[0m     layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[1;32m   1053\u001b[0m         hidden_states,\n\u001b[1;32m   1054\u001b[0m         attention_mask\u001b[39m=\u001b[39;49mextended_attention_mask,\n\u001b[1;32m   1055\u001b[0m         position_bias\u001b[39m=\u001b[39;49mposition_bias,\n\u001b[1;32m   1056\u001b[0m         encoder_hidden_states\u001b[39m=\u001b[39;49mencoder_hidden_states,\n\u001b[1;32m   1057\u001b[0m         encoder_attention_mask\u001b[39m=\u001b[39;49mencoder_extended_attention_mask,\n\u001b[1;32m   1058\u001b[0m         encoder_decoder_position_bias\u001b[39m=\u001b[39;49mencoder_decoder_position_bias,\n\u001b[1;32m   1059\u001b[0m         layer_head_mask\u001b[39m=\u001b[39;49mlayer_head_mask,\n\u001b[1;32m   1060\u001b[0m         cross_attn_layer_head_mask\u001b[39m=\u001b[39;49mcross_attn_layer_head_mask,\n\u001b[1;32m   1061\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mpast_key_value,\n\u001b[1;32m   1062\u001b[0m         use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m   1063\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m   1064\u001b[0m     )\n\u001b[1;32m   1066\u001b[0m \u001b[39m# layer_outputs is a tuple with:\u001b[39;00m\n\u001b[1;32m   1067\u001b[0m \u001b[39m# hidden-states, key-value-states, (self-attention position bias), (self-attention weights), (cross-attention position bias), (cross-attention weights)\u001b[39;00m\n\u001b[1;32m   1068\u001b[0m \u001b[39mif\u001b[39;00m use_cache \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n",
      "File \u001b[0;32m~/task-search-quality/env/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/task-search-quality/env/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:684\u001b[0m, in \u001b[0;36mT5Block.forward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, encoder_hidden_states, encoder_attention_mask, encoder_decoder_position_bias, layer_head_mask, cross_attn_layer_head_mask, past_key_value, use_cache, output_attentions, return_dict)\u001b[0m\n\u001b[1;32m    681\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    682\u001b[0m     self_attn_past_key_value, cross_attn_past_key_value \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 684\u001b[0m self_attention_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayer[\u001b[39m0\u001b[39;49m](\n\u001b[1;32m    685\u001b[0m     hidden_states,\n\u001b[1;32m    686\u001b[0m     attention_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    687\u001b[0m     position_bias\u001b[39m=\u001b[39;49mposition_bias,\n\u001b[1;32m    688\u001b[0m     layer_head_mask\u001b[39m=\u001b[39;49mlayer_head_mask,\n\u001b[1;32m    689\u001b[0m     past_key_value\u001b[39m=\u001b[39;49mself_attn_past_key_value,\n\u001b[1;32m    690\u001b[0m     use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m    691\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    692\u001b[0m )\n\u001b[1;32m    693\u001b[0m hidden_states, present_key_value_state \u001b[39m=\u001b[39m self_attention_outputs[:\u001b[39m2\u001b[39m]\n\u001b[1;32m    694\u001b[0m attention_outputs \u001b[39m=\u001b[39m self_attention_outputs[\u001b[39m2\u001b[39m:]  \u001b[39m# Keep self-attention outputs and relative position weights\u001b[39;00m\n",
      "File \u001b[0;32m~/task-search-quality/env/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/task-search-quality/env/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:590\u001b[0m, in \u001b[0;36mT5LayerSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, position_bias, layer_head_mask, past_key_value, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    579\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    580\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    581\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    587\u001b[0m     output_attentions\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    588\u001b[0m ):\n\u001b[1;32m    589\u001b[0m     normed_hidden_states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer_norm(hidden_states)\n\u001b[0;32m--> 590\u001b[0m     attention_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mSelfAttention(\n\u001b[1;32m    591\u001b[0m         normed_hidden_states,\n\u001b[1;32m    592\u001b[0m         mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    593\u001b[0m         position_bias\u001b[39m=\u001b[39;49mposition_bias,\n\u001b[1;32m    594\u001b[0m         layer_head_mask\u001b[39m=\u001b[39;49mlayer_head_mask,\n\u001b[1;32m    595\u001b[0m         past_key_value\u001b[39m=\u001b[39;49mpast_key_value,\n\u001b[1;32m    596\u001b[0m         use_cache\u001b[39m=\u001b[39;49muse_cache,\n\u001b[1;32m    597\u001b[0m         output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    598\u001b[0m     )\n\u001b[1;32m    599\u001b[0m     hidden_states \u001b[39m=\u001b[39m hidden_states \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout(attention_output[\u001b[39m0\u001b[39m])\n\u001b[1;32m    600\u001b[0m     outputs \u001b[39m=\u001b[39m (hidden_states,) \u001b[39m+\u001b[39m attention_output[\u001b[39m1\u001b[39m:]  \u001b[39m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[0;32m~/task-search-quality/env/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/task-search-quality/env/lib/python3.10/site-packages/transformers/models/t5/modeling_t5.py:520\u001b[0m, in \u001b[0;36mT5Attention.forward\u001b[0;34m(self, hidden_states, mask, key_value_states, position_bias, past_key_value, layer_head_mask, query_length, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    515\u001b[0m value_states \u001b[39m=\u001b[39m project(\n\u001b[1;32m    516\u001b[0m     hidden_states, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mv, key_value_states, past_key_value[\u001b[39m1\u001b[39m] \u001b[39mif\u001b[39;00m past_key_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    517\u001b[0m )\n\u001b[1;32m    519\u001b[0m \u001b[39m# compute scores\u001b[39;00m\n\u001b[0;32m--> 520\u001b[0m scores \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mmatmul(\n\u001b[1;32m    521\u001b[0m     query_states, key_states\u001b[39m.\u001b[39;49mtranspose(\u001b[39m3\u001b[39;49m, \u001b[39m2\u001b[39;49m)\n\u001b[1;32m    522\u001b[0m )  \u001b[39m# equivalent of torch.einsum(\"bnqd,bnkd->bnqk\", query_states, key_states), compatible with onnx op>9\u001b[39;00m\n\u001b[1;32m    524\u001b[0m \u001b[39mif\u001b[39;00m position_bias \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    525\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhas_relative_attention_bias:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# create run files\n",
    "print(\"Creating run files \")\n",
    "for domain, index_models in models.items():\n",
    "    qs = queries[domain]\n",
    "    print(f\"DOMAIN {domain}\")\n",
    "    for model_name, model in index_models.items():\n",
    "        model.convert_search_results_to_run(qs)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty judgments\n",
    "print(\"Creating empty judgments\")\n",
    "for domain, index_models in models.items():\n",
    "    qs = queries[domain]\n",
    "    print(f\"DOMAIN {domain}\")\n",
    "    for model_name, model in index_models.items():\n",
    "        model.create_empty_judgments(qs, k=50, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models_indexes.marqo_model import MarqoModel\n",
    "marqo_diy = MarqoModel(domain = \"DIY\")\n",
    "marqo_diy.build_index()\n",
    "# marqo_diy.search(\"cleaning \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Build indexes from datasets \"\"\"\n",
    "\n",
    "# from models_indexes.bm25_model import BM25Model\n",
    "\n",
    "# bm25 = BM25Model(domain = \"DIY\", t5=True)\n",
    "# bm25.build_index()\n",
    "\n",
    "# from models_indexes.ance_model import AnceModel\n",
    "# ance: AnceModel = AnceModel(domain = \"DIY\")\n",
    "# bm25.build_index()\n",
    "\n",
    "# # bm25_cooking = BM25Model(domain = \"DIY\", t5=True)\n",
    "# # bm25_cooking.build_index()\n",
    "\n",
    "# from models_indexes.colbert_model import ColbertModel\n",
    "# colbert: ColbertModel = ColbertModel(domain = \"DIY\")\n",
    "# colbert.build_index()\n",
    "\n",
    "# query = queries[\"COOKING\"][\"target query\"][0]\n",
    "# query = \"pizza\"\n",
    "# colbert_cooking.search(query)\n",
    "# colbert_diy.convert_search_results_to_run()\n",
    "# colbert_diy.create_empty_judgments()\n",
    "\n",
    "# from models_indexes.ance_model import AnceModel\n",
    "# ance: AnceModel = AnceModel(domain = \"COOKING\")\n",
    "# ance.build_index()\n",
    "# ance.search(\"easi dessert christma\")\n",
    "\n",
    "# from models_indexes.colbert_model import ColbertModel\n",
    "# colbert: ColbertModel = ColbertModel(domain = \"COOKING\")\n",
    "# colbert.build_index()\n",
    "# colbert.search(\"pizza\")\n",
    "\n",
    "# from models_indexes.colbert_model import ColbertModel\n",
    "# colbert: ColbertModel = ColbertModel(domain = \"DIY\")\n",
    "# colbert.build_index()\n",
    "# colbert.search(\"kitchen\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models_indexes.colbert_model import ColbertModel\n",
    "colbert: ColbertModel = ColbertModel(domain = \"COOKING\")\n",
    "colbert.build_index()\n",
    "colbert.search(\"fish\")\n",
    "\n",
    "# marqo_cooking = MarqoModel(domain = \"COOKING\")\n",
    "# marqo_cooking.build_index()\n",
    "# marqo_cooking.search(\"fish\")\n",
    "\n",
    "# queries_path = os.path.join(os.getcwd(), \"queries\", \"cooking.csv\")\n",
    "\n",
    "# pd_cooking_queries = pd.read_csv(queries_path).iloc[:10]\n",
    "# bm25_food.convert_search_results_to_run(pd_cooking_queries)\n",
    "# bm25_food.create_empty_judgments(pd_cooking_queries, 5)\n",
    "# queries_path = os.path.join(os.getcwd(), \"queries\", \"diy.csv\")\n",
    "# pd_diy_queries = pd.read_csv(queries_path).iloc[:10]\n",
    "# ance_diy.build_index()\n",
    "# ance_diy.convert_search_results_to_run(pd_diy_queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ance_cooking = AnceModel(domain = \"COOKING\")\n",
    "# ance_cooking.build_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from models_indexes.bm25_model import BM25Model\n",
    "# bm25_cooking = BM25Model(domain = \"COOKING\")\n",
    "# bm25_cooking.build_index()\n",
    "\n",
    "# queries_path = os.path.join(os.getcwd(), \"queries\", \"cooking.csv\")\n",
    "# pd_cooking_queries = pd.read_csv(queries_path).iloc[:10]\n",
    "# query = \"granola\"\n",
    "# bm25_cooking.search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5fc5ba0db375a557a527168d68cfbe4f022bc62df7af9d8f86e24130294f8f8e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
