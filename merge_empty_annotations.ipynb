{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "annotations per topic 66.57\n",
      "annotations per topic 34.7\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "domains = [\"cooking\", \"diy\"]\n",
    "\n",
    "\n",
    "for domain in domains:\n",
    "\n",
    "    k = 10\n",
    "\n",
    "    run_files_path = f\"measurements/{domain}/run_files\"\n",
    "    run_files = os.listdir(run_files_path)\n",
    "\n",
    "    annotation_set = set()\n",
    "\n",
    "    for file in run_files:\n",
    "        if not file.endswith(\".run\"):\n",
    "            continue\n",
    "        with open(os.path.join(os.getcwd(), run_files_path, file), \"r\") as f:\n",
    "            # runs = [run for run in f]\n",
    "            for run in f:\n",
    "                run_components = \" \".join(run.split(' ')[0:3])\n",
    "                # print(run)\n",
    "                if int(run.split(' ')[3]) <= k:\n",
    "                    annotation_set.add(run_components)\n",
    "    \n",
    "    k = 5\n",
    "    \n",
    "    run_files_path = f\"measurements/{domain}/run_files/marqo-filters\"\n",
    "    run_files = os.listdir(run_files_path)\n",
    "    for file in run_files:\n",
    "        if not file.endswith(\".run\"):\n",
    "            continue\n",
    "        with open(os.path.join(os.getcwd(), run_files_path, file), \"r\") as f:\n",
    "            # runs = [run for run in f]\n",
    "            for run in f:\n",
    "                run_components = \" \".join(run.split(' ')[0:3])\n",
    "                # print(run)\n",
    "                if int(run.split(' ')[3]) <= k:\n",
    "                    annotation_set.add(run_components)\n",
    "\n",
    "    empty_annotations = sorted(annotation_set)\n",
    "\n",
    "    queries = pd.read_csv(f'queries/{domain}.csv')\n",
    "\n",
    "    print(\"annotations per topic\", len(empty_annotations) / 100)\n",
    "\n",
    "    annotations_list = []\n",
    "\n",
    "    for annotations in empty_annotations:\n",
    "        query_id, _, taskgraph_id = annotations.split(' ')\n",
    "        # print(query_id)\n",
    "        raw_query = queries[queries[\"id\"] == query_id].iloc[0][\"raw query\"]\n",
    "        annotations_list.append({\n",
    "            \"query-id\": query_id,\n",
    "            \"raw query\": raw_query,\n",
    "            \"taskgraph-id\": taskgraph_id,\n",
    "        })\n",
    "\n",
    "    empty_annotations_path = f\"measurements/{domain}/empty_annotations\"\n",
    "    df = pd.DataFrame(annotations_list)\n",
    "    df.to_csv(os.path.join(os.getcwd(), empty_annotations_path, f\"annotations-all.csv\"), index=False)\n",
    "# queries[\"id\"]\n",
    "\n",
    "# with open(os.path.join(os.getcwd(), empty_annotations_path, 'combined_annotations.csv'), \"r\") as f:\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from google.protobuf.json_format import MessageToDict\n",
    "import json\n",
    "from google.protobuf.json_format import Parse\n",
    "from pyserini.search import LuceneSearcher\n",
    "\n",
    "from taskmap_pb2 import TaskMap\n",
    "\n",
    "def get_taskgraph(id, domain):\n",
    "    # print(os.path.join(os.getcwd(), \"indexes\", domain, \"system_index_sparse\"))\n",
    "    taskmap_index_path = os.path.join(os.getcwd(), \"indexes\", domain, \"system_index_sparse\")\n",
    "    searcher = LuceneSearcher(index_dir=taskmap_index_path)\n",
    "    id = id.replace('\\n','')\n",
    "    doc = searcher.doc(docid=id)\n",
    "    taskmap_json = json.loads(doc.raw())['recipe_document_json']\n",
    "    taskmap = Parse(json.dumps(taskmap_json), TaskMap())\n",
    "    return taskmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query-0,how to spatchcock a turkey,cooking+recipe1m+0c118e37afefd6deb9ba92bd544a304b\n",
      "\n",
      "6658\n",
      "('query-0', 'cooking+recipe1m+06c38e07b3533c34738b86f379aafe5c')\n",
      "7359\n",
      "7359\n"
     ]
    }
   ],
   "source": [
    "# get missing annotations\n",
    "import csv \n",
    "updated_annotations_path = \"measurements/cooking/empty_annotations/annotations-all.csv\"\n",
    "# updated_annotations_path2 = \"measurements/cooking/empty_annotations/marqo-annotations-5.csv\"\n",
    "# new_annotations_path = \"measurements/cooking/empty_annotations/empty_annotations-10.csv\"\n",
    "qrels_path = \"/home/ubuntu/task-search-quality/measurements/judgments/cooking.qrels\"\n",
    "\n",
    "judgments_csv = \"measurements/cooking/empty_annotations/missing-judgments3.csv\"\n",
    "queries = pd.read_csv('queries/cooking.csv')\n",
    "\n",
    "with open(updated_annotations_path, \"r\") as f:\n",
    "    updated_annotations = [line for line in f]\n",
    "    print(updated_annotations[1])\n",
    "    print(len(updated_annotations))\n",
    "    \n",
    "with open(qrels_path, \"r\") as f:\n",
    "    annotations_done = [line.strip().split(\" \") for line in f]\n",
    "    annotations_dict = {}\n",
    "    for a in annotations_done:\n",
    "        q_id, _, task_id, rel = a\n",
    "        annotations_dict[(q_id, task_id)] = rel\n",
    "    # print(annotations_done[1])\n",
    "    # print(len(annotations_done))\n",
    "    keys = [key for key in annotations_dict.keys()]\n",
    "    print(keys[0])\n",
    "\n",
    "annotations_list = []\n",
    "for l in updated_annotations[1:]:\n",
    "    l = l.strip()\n",
    "    q_id, task_id = l.split(',')[0], l.split(',')[2]\n",
    "    # print(q_id, task_id)\n",
    "    # print((q_id, task_id))\n",
    "    if (q_id, task_id) in annotations_dict:\n",
    "        rel = annotations_dict[(q_id, task_id)]\n",
    "        del annotations_dict[(q_id, task_id)]\n",
    "    else:\n",
    "        rel = ''\n",
    "    taskmap = get_taskgraph(task_id, \"cooking\")\n",
    "    query_raw = queries[queries[\"id\"] == q_id].iloc[0]\n",
    "    \n",
    "    annotations_list.append([q_id, task_id, query_raw[\"raw query\"], taskmap.title, taskmap.source_url, rel,])\n",
    "\n",
    "for (q_id, task_id), rel in annotations_dict.items():\n",
    "    taskmap = get_taskgraph(task_id, \"cooking\")\n",
    "    query = queries[queries[\"id\"] == q_id].iloc[0]\n",
    "    annotations_list.append([q_id, task_id, query[\"raw query\"], taskmap.title, taskmap.source_url, rel,])\n",
    "\n",
    "print(len(annotations_list))\n",
    "annotations_list = sorted(annotations_list)\n",
    "\n",
    "print(len(annotations_list))\n",
    "\n",
    "with open(judgments_csv,'w') as result_file:\n",
    "    wr = csv.writer(result_file, delimiter=',')\n",
    "    wr.writerows(annotations_list)\n",
    "# print(diff_annotations)\n",
    "    \n",
    "# diff_annotations =  list(updated_annotations.difference(annotations))\n",
    "# diff_annotations = [a.strip().split(',') for a in diff_annotations]\n",
    "\n",
    "\n",
    "# len(diff_annotations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, 'compiled_protobufs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hits': [], 'processingTimeMs': 35, 'query': 'fix a fridge', 'limit': 10}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models_indexes.marqo_model import MarqoModel\n",
    "from models_indexes.abstract_model import AbstractModel\n",
    "\n",
    "models = {}\n",
    "\n",
    "# for domain in  [\"DIY\", \"COOKING\"]:\n",
    "for domain in  [\"DIY\"]:\n",
    "    models[domain] = {\n",
    "        # \"bm25\" : BM25Model(domain = domain),\n",
    "        # \"bm25+rm3\" : BM25Model(domain = domain, rm3=True),\n",
    "        # \"bm25+t5\" : BM25Model(domain = domain, t5=True),\n",
    "        # \"bm25+rm3+t5\" : BM25Model(domain = domain, rm3=True, t5=True),\n",
    "        # \"ance\": AnceModel(domain = domain),\n",
    "        # \"colbert\": ColbertModel(domain = domain),\n",
    "        \"marqo\": MarqoModel(domain = domain),\n",
    "    }\n",
    "    \n",
    "models[\"DIY\"][\"marqo\"].search(\"fix a fridge\")\n",
    "# models[\"DIY\"][\"marqo\"].search(\"fridge\")\n",
    "# models[\"DIY\"][\"marqo\"].get_stats()\n",
    "models[\"DIY\"][\"marqo\"].get_single_document(\"diy+wikihow-offline+4e3c05e275eed0c1b2572ac770139c52\")\n",
    "# print(\"Creating run files \")\n",
    "# for domain, index_models in models.items():\n",
    "#     qs = queries[domain]\n",
    "#     print(f\"DOMAIN {domain}\")\n",
    "#     for model_name, model in index_models.items():\n",
    "#         model.convert_search_results_to_run(qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query-6 Q0 diy+wikihow-offline+3f5716a7d0530fcb662a9cc257419c7f 0\n",
      "query-43 Q0 diy+wikihow-offline+5275a81226a3568e6b8559c77ce16c98 0\n",
      "{('query-6', 'diy+wikihow-offline+3f5716a7d0530fcb662a9cc257419c7f'), ('query-43', 'diy+wikihow-offline+5275a81226a3568e6b8559c77ce16c98')}\n"
     ]
    }
   ],
   "source": [
    "run_file = \"/home/ubuntu/task-search-quality/measurements/diy/run_files/ance.run\"\n",
    "qrels_file = \"/home/ubuntu/task-search-quality/measurements/judgments/diy.qrels\"\n",
    "\n",
    "def find_missing_runs(run_file, qrels_file, k = 10):\n",
    "    with open(run_file, \"r\") as f:\n",
    "        runs = [line.strip().split(\" \") for line in f]\n",
    "        for run in runs:\n",
    "            run[3] = int(run[3])\n",
    "            run[4] = float(run[4])\n",
    "        runs = [run for run in runs if run[3] <= 10]\n",
    "        runs = {(run[0],run[2]) for run in runs}\n",
    "    # print(runs[:10])\n",
    "        \n",
    "    with open(qrels_file, \"r\") as f:\n",
    "        qrels = [line.strip().split(\" \") for line in f]\n",
    "        qrels = {(qrel[0], qrel[2]) for qrel in qrels}\n",
    "    # print(qrels[:10])\n",
    "    dif = runs.difference(qrels)\n",
    "    for d in dif:\n",
    "        print(f'{d[0]} Q0 {d[1]} 0')\n",
    "    print(dif)\n",
    "    \n",
    "find_missing_runs(run_file, qrels_file)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = \"/home/ubuntu/task-search-quality/measurements/judgments/diy2.qrels\"\n",
    "path2 = \"/home/ubuntu/task-search-quality/measurements/judgments/diy.qrels\"\n",
    "\n",
    "with open(path1, \"r\") as f:\n",
    "    r1 = {r for r in f}\n",
    "\n",
    "with open(path2, \"r\") as f:\n",
    "    r2 = {r for r in f}\n",
    "runs = r1.union(r2)\n",
    "runs_sorted =  sorted(list(runs))\n",
    "\n",
    "path3 = \"/home/ubuntu/task-search-quality/measurements/judgments/diy-all.qrels\"\n",
    "\n",
    "with open(path3, \"w\") as f:\n",
    "    f.writelines(runs_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e524aa708618ab8d8f753ac1f2022f3e8661ea3a5ed96feef0a7d789cff7a903"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
