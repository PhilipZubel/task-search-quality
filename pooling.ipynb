{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "domains = [\"cooking\", \"diy\"]\n",
    "\n",
    "\n",
    "for domain in domains:\n",
    "\n",
    "    k = 10 # pooling \n",
    "    run_files_path = f\"measurements/{domain}/run_files\"\n",
    "    run_files = os.listdir(run_files_path) ## get all runs\n",
    "\n",
    "    annotation_set = set() # create set of pooled annotations\n",
    "\n",
    "    for file in run_files:\n",
    "        if not file.endswith(\".run\"):\n",
    "            continue\n",
    "        with open(os.path.join(os.getcwd(), run_files_path, file), \"r\") as f:\n",
    "            for run in f:\n",
    "                run_components = \" \".join(run.split(' ')[0:3])\n",
    "                if int(run.split(' ')[3]) <= k:\n",
    "                    annotation_set.add(run_components)\n",
    "    \n",
    "    \n",
    "    ## Pooling for MiniLM-L6 fielded retrieval\n",
    "    k = 5\n",
    "    run_files_path = f\"measurements/{domain}/run_files/marqo-filters\"\n",
    "    run_files = os.listdir(run_files_path)\n",
    "    for file in run_files:\n",
    "        if not file.endswith(\".run\"):\n",
    "            continue\n",
    "        with open(os.path.join(os.getcwd(), run_files_path, file), \"r\") as f:\n",
    "            for run in f:\n",
    "                run_components = \" \".join(run.split(' ')[0:3])\n",
    "                if int(run.split(' ')[3]) <= k:\n",
    "                    annotation_set.add(run_components)\n",
    "\n",
    "    empty_annotations = sorted(annotation_set)\n",
    "\n",
    "    queries = pd.read_csv(f'queries/{domain}.csv')\n",
    "\n",
    "\n",
    "    annotations_list = []\n",
    "\n",
    "    for annotations in empty_annotations:\n",
    "        query_id, _, taskgraph_id = annotations.split(' ')\n",
    "        # print(query_id)\n",
    "        raw_query = queries[queries[\"id\"] == query_id].iloc[0][\"raw query\"]\n",
    "        annotations_list.append({\n",
    "            \"query-id\": query_id,\n",
    "            \"raw query\": raw_query,\n",
    "            \"taskgraph-id\": taskgraph_id,\n",
    "        })\n",
    "\n",
    "    empty_annotations_path = f\"measurements/{domain}/empty_annotations\"\n",
    "    df = pd.DataFrame(annotations_list)\n",
    "    df.to_csv(os.path.join(os.getcwd(), empty_annotations_path, f\"annotations-all.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from google.protobuf.json_format import MessageToDict\n",
    "import json\n",
    "from google.protobuf.json_format import Parse\n",
    "from pyserini.search import LuceneSearcher\n",
    "\n",
    "from taskmap_pb2 import TaskMap\n",
    "\n",
    "def get_taskgraph(id, domain):\n",
    "    # print(os.path.join(os.getcwd(), \"indexes\", domain, \"system_index_sparse\"))\n",
    "    taskmap_index_path = os.path.join(os.getcwd(), \"indexes\", domain, \"system_index_sparse\")\n",
    "    searcher = LuceneSearcher(index_dir=taskmap_index_path)\n",
    "    id = id.replace('\\n','')\n",
    "    doc = searcher.doc(docid=id)\n",
    "    taskmap_json = json.loads(doc.raw())['recipe_document_json']\n",
    "    taskmap = Parse(json.dumps(taskmap_json), TaskMap())\n",
    "    return taskmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # get missing annotations\n",
    "# import csv \n",
    "# updated_annotations_path = \"measurements/cooking/empty_annotations/annotations-all.csv\"\n",
    "# # updated_annotations_path2 = \"measurements/cooking/empty_annotations/marqo-annotations-5.csv\"\n",
    "# # new_annotations_path = \"measurements/cooking/empty_annotations/empty_annotations-10.csv\"\n",
    "# qrels_path = \"/home/ubuntu/task-search-quality/measurements/judgments/cooking.qrels\"\n",
    "\n",
    "# judgments_csv = \"measurements/cooking/empty_annotations/missing-judgments3.csv\"\n",
    "# queries = pd.read_csv('queries/cooking.csv')\n",
    "\n",
    "# with open(updated_annotations_path, \"r\") as f:\n",
    "#     updated_annotations = [line for line in f]\n",
    "#     print(updated_annotations[1])\n",
    "#     print(len(updated_annotations))\n",
    "    \n",
    "# with open(qrels_path, \"r\") as f:\n",
    "#     annotations_done = [line.strip().split(\" \") for line in f]\n",
    "#     annotations_dict = {}\n",
    "#     for a in annotations_done:\n",
    "#         q_id, _, task_id, rel = a\n",
    "#         annotations_dict[(q_id, task_id)] = rel\n",
    "#     # print(annotations_done[1])\n",
    "#     # print(len(annotations_done))\n",
    "#     keys = [key for key in annotations_dict.keys()]\n",
    "#     print(keys[0])\n",
    "\n",
    "# annotations_list = []\n",
    "# for l in updated_annotations[1:]:\n",
    "#     l = l.strip()\n",
    "#     q_id, task_id = l.split(',')[0], l.split(',')[2]\n",
    "#     # print(q_id, task_id)\n",
    "#     # print((q_id, task_id))\n",
    "#     if (q_id, task_id) in annotations_dict:\n",
    "#         rel = annotations_dict[(q_id, task_id)]\n",
    "#         del annotations_dict[(q_id, task_id)]\n",
    "#     else:\n",
    "#         rel = ''\n",
    "#     taskmap = get_taskgraph(task_id, \"cooking\")\n",
    "#     query_raw = queries[queries[\"id\"] == q_id].iloc[0]\n",
    "    \n",
    "#     annotations_list.append([q_id, task_id, query_raw[\"raw query\"], taskmap.title, taskmap.source_url, rel,])\n",
    "\n",
    "# for (q_id, task_id), rel in annotations_dict.items():\n",
    "#     taskmap = get_taskgraph(task_id, \"cooking\")\n",
    "#     query = queries[queries[\"id\"] == q_id].iloc[0]\n",
    "#     annotations_list.append([q_id, task_id, query[\"raw query\"], taskmap.title, taskmap.source_url, rel,])\n",
    "\n",
    "# print(len(annotations_list))\n",
    "# annotations_list = sorted(annotations_list)\n",
    "\n",
    "# print(len(annotations_list))\n",
    "\n",
    "# with open(judgments_csv,'w') as result_file:\n",
    "#     wr = csv.writer(result_file, delimiter=',')\n",
    "#     wr.writerows(annotations_list)\n",
    "# print(diff_annotations)\n",
    "    \n",
    "# diff_annotations =  list(updated_annotations.difference(annotations))\n",
    "# diff_annotations = [a.strip().split(',') for a in diff_annotations]\n",
    "\n",
    "\n",
    "# len(diff_annotations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "\n",
    "# sys.path.insert(0, 'compiled_protobufs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from models_indexes.marqo_model import MarqoModel\n",
    "# from models_indexes.abstract_model import AbstractModel\n",
    "\n",
    "# models = {}\n",
    "\n",
    "# # for domain in  [\"DIY\", \"COOKING\"]:\n",
    "# for domain in  [\"DIY\"]:\n",
    "#     models[domain] = {\n",
    "#         # \"bm25\" : BM25Model(domain = domain),\n",
    "#         # \"bm25+rm3\" : BM25Model(domain = domain, rm3=True),\n",
    "#         # \"bm25+t5\" : BM25Model(domain = domain, t5=True),\n",
    "#         # \"bm25+rm3+t5\" : BM25Model(domain = domain, rm3=True, t5=True),\n",
    "#         # \"ance\": AnceModel(domain = domain),\n",
    "#         # \"colbert\": ColbertModel(domain = domain),\n",
    "#         \"marqo\": MarqoModel(domain = domain),\n",
    "#     }\n",
    "    \n",
    "# models[\"DIY\"][\"marqo\"].search(\"fix a fridge\")\n",
    "# # models[\"DIY\"][\"marqo\"].search(\"fridge\")\n",
    "# # models[\"DIY\"][\"marqo\"].get_stats()\n",
    "# models[\"DIY\"][\"marqo\"].get_single_document(\"diy+wikihow-offline+4e3c05e275eed0c1b2572ac770139c52\")\n",
    "# # print(\"Creating run files \")\n",
    "# # for domain, index_models in models.items():\n",
    "# #     qs = queries[domain]\n",
    "# #     print(f\"DOMAIN {domain}\")\n",
    "# #     for model_name, model in index_models.items():\n",
    "# #         model.convert_search_results_to_run(qs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run_file = \"/home/ubuntu/task-search-quality/measurements/diy/run_files/ance.run\"\n",
    "# qrels_file = \"/home/ubuntu/task-search-quality/measurements/judgments/diy.qrels\"\n",
    "\n",
    "# def find_missing_runs(run_file, qrels_file, k = 10):\n",
    "#     with open(run_file, \"r\") as f:\n",
    "#         runs = [line.strip().split(\" \") for line in f]\n",
    "#         for run in runs:\n",
    "#             run[3] = int(run[3])\n",
    "#             run[4] = float(run[4])\n",
    "#         runs = [run for run in runs if run[3] <= 10]\n",
    "#         runs = {(run[0],run[2]) for run in runs}\n",
    "#     # print(runs[:10])\n",
    "        \n",
    "#     with open(qrels_file, \"r\") as f:\n",
    "#         qrels = [line.strip().split(\" \") for line in f]\n",
    "#         qrels = {(qrel[0], qrel[2]) for qrel in qrels}\n",
    "#     # print(qrels[:10])\n",
    "#     dif = runs.difference(qrels)\n",
    "#     for d in dif:\n",
    "#         print(f'{d[0]} Q0 {d[1]} 0')\n",
    "#     print(dif)\n",
    "    \n",
    "# find_missing_runs(run_file, qrels_file)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path1 = \"/home/ubuntu/task-search-quality/measurements/judgments/diy2.qrels\"\n",
    "# path2 = \"/home/ubuntu/task-search-quality/measurements/judgments/diy.qrels\"\n",
    "\n",
    "# with open(path1, \"r\") as f:\n",
    "#     r1 = {r for r in f}\n",
    "\n",
    "# with open(path2, \"r\") as f:\n",
    "#     r2 = {r for r in f}\n",
    "# runs = r1.union(r2)\n",
    "# runs_sorted =  sorted(list(runs))\n",
    "\n",
    "# path3 = \"/home/ubuntu/task-search-quality/measurements/judgments/diy-all.qrels\"\n",
    "\n",
    "# with open(path3, \"w\") as f:\n",
    "#     f.writelines(runs_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e524aa708618ab8d8f753ac1f2022f3e8661ea3a5ed96feef0a7d789cff7a903"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
