{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "import json\n",
    "from google.protobuf.json_format import Parse\n",
    "\n",
    "sys.path.insert(0, 'compiled_protobufs')\n",
    "from taskmap_pb2 import TaskMap\n",
    "\n",
    "queries_path = os.path.join(os.getcwd(), \"datasets\", \"queries\", \"cooking_queries.csv\")\n",
    "qrels_path = os.path.join(os.getcwd(), 'datasets', 'qrles', 'qrles.qrles')\n",
    "annotations_path = os.path.join(os.getcwd(), 'datasets', 'judgments', 'cooking-annotations.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save qrels files\n",
    "\n",
    "with open(qrels_path, \"w\") as f:\n",
    "    pd_annotations = pd.read_csv(annotations_path)\n",
    "    lines = []\n",
    "    # print(pd_annotations.head())\n",
    "    for idx, annotation in pd_annotations.iterrows():\n",
    "        q_id, doc_id, score = annotation[\"query-id\"], annotation[\"doc-id\"], annotation[\"relevance\"]\n",
    "        lines.append(f'{q_id} Q0 {doc_id} {score}\\n')\n",
    "    lines[-1] = lines[-1].replace(\"\\n\",\"\")\n",
    "    f.writelines(lines)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_path = os.path.join(os.getcwd(), 'datasets', 'qrles')\n",
    "taskmap_cooking_index_path = os.path.join(os.getcwd(), \"indexes\", \"food\", \"system_index_sparse\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyserini.search import LuceneSearcher\n",
    "sys.path.insert(0, './pygaggle')\n",
    "from pygaggle.rerank.base import Query, Text, hits_to_texts\n",
    "from pygaggle.rerank.transformer import MonoT5\n",
    "\n",
    "config = [\n",
    "    \"bm25\",\n",
    "    \"bm25+rm3\",\n",
    "    \"bm25+t5\",\n",
    "    \"bm25+rm3+t5\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialize searcher bm25\n",
      "Initialize searcher bm25\n",
      "Initialize searcher bm25\n",
      "Initialize searcher bm25\n",
      "Initialize searcher bm25\n",
      "Initialize searcher bm25\n",
      "Initialize searcher bm25\n",
      "Initialize searcher bm25\n",
      "Initialize searcher bm25\n",
      "Initialize searcher bm25\n",
      "Initialize searcher bm25+rm3\n",
      "Initialize searcher bm25+rm3\n",
      "Initialize searcher bm25+rm3\n",
      "Initialize searcher bm25+rm3\n",
      "Initialize searcher bm25+rm3\n",
      "Initialize searcher bm25+rm3\n",
      "Initialize searcher bm25+rm3\n",
      "Initialize searcher bm25+rm3\n",
      "Initialize searcher bm25+rm3\n",
      "Initialize searcher bm25+rm3\n",
      "Initialize searcher bm25+t5\n",
      "Initialize searcher bm25+t5\n",
      "Initialize searcher bm25+t5\n",
      "Initialize searcher bm25+t5\n",
      "Initialize searcher bm25+t5\n",
      "Initialize searcher bm25+t5\n",
      "Initialize searcher bm25+t5\n",
      "Initialize searcher bm25+t5\n",
      "Initialize searcher bm25+t5\n",
      "Initialize searcher bm25+t5\n",
      "Initialize searcher bm25+rm3+t5\n",
      "Initialize searcher bm25+rm3+t5\n",
      "Initialize searcher bm25+rm3+t5\n",
      "Initialize searcher bm25+rm3+t5\n",
      "Initialize searcher bm25+rm3+t5\n",
      "Initialize searcher bm25+rm3+t5\n",
      "Initialize searcher bm25+rm3+t5\n",
      "Initialize searcher bm25+rm3+t5\n",
      "Initialize searcher bm25+rm3+t5\n",
      "Initialize searcher bm25+rm3+t5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "cooking_queries = pd.read_csv(queries_path).iloc[:10]\n",
    "reranker =  MonoT5()\n",
    "\n",
    "def get_searcher(search_model):\n",
    "    if search_model == \"bm25\" or search_model == \"bm25+t5\":\n",
    "        searcher = LuceneSearcher(index_dir=taskmap_cooking_index_path)\n",
    "        searcher.set_bm25(b=0.4, k1=0.9)\n",
    "    if search_model == \"bm25+rm3\" or search_model == \"bm25+rm3+t5\":\n",
    "        searcher = LuceneSearcher(index_dir=taskmap_cooking_index_path)\n",
    "        searcher.set_bm25(b=0.4, k1=0.9)\n",
    "        searcher.set_rm3(fb_terms=10, fb_docs=10, original_query_weight=0.5)\n",
    "    return searcher\n",
    "\n",
    "for model in config:\n",
    "    lines = []\n",
    "    for idx, query in cooking_queries.iterrows():\n",
    "        print(f\"Initialize searcher {model}\")\n",
    "        searcher = get_searcher(model)\n",
    "        hits = searcher.search(q=query[\"target query\"], k=50)\n",
    "        if \"t5\" in model:\n",
    "            hits = reranker.rerank(Query(query[\"target query\"]), hits_to_texts(hits))\n",
    "        for rank, hit in enumerate(hits):\n",
    "            if type(hit) == Text:\n",
    "                doc_json = json.loads(hit.text)\n",
    "            else:\n",
    "                doc_json = json.loads(hit.raw)\n",
    "            taskmap_json = doc_json['recipe_document_json']\n",
    "            taskmap = Parse(json.dumps(taskmap_json), TaskMap())\n",
    "            doc_id = taskmap.taskmap_id\n",
    "            line = f'query-{idx} Q0 {doc_id} {rank+1} {hit.score} bm25\\n'\n",
    "            lines.append(line)\n",
    "    lines[-1] = lines[-1].replace(\"\\n\",\"\")\n",
    "\n",
    "    with open(os.path.join(run_path, model+\".run\"), \"w\") as f:\n",
    "        f.writelines(lines)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/philip/task-search-quality/datasets/qrles/bm25.run\n",
      "bm25: {P@3: 0.5666666666666667, R@3: 0.49499999999999994, nDCG@3: 0.5578509669245213}\n",
      "/home/philip/task-search-quality/datasets/qrles/bm25+rm3.run\n",
      "bm25+rm3: {P@3: 0.39999999999999997, R@3: 0.35, nDCG@3: 0.3953221626202607}\n",
      "/home/philip/task-search-quality/datasets/qrles/bm25+t5.run\n",
      "bm25+t5: {P@3: 0.2333333333333333, R@3: 0.19666666666666663, nDCG@3: 0.2092284198678045}\n",
      "/home/philip/task-search-quality/datasets/qrles/bm25+rm3+t5.run\n",
      "bm25+rm3+t5: {P@3: 0.3, R@3: 0.2633333333333333, nDCG@3: 0.2561562924700801}\n"
     ]
    }
   ],
   "source": [
    "import ir_measures\n",
    "from ir_measures import *\n",
    "\n",
    "# qrles = ir_measures.read_trec_qrels('qrels/qrls.qrles')\n",
    "# run = ir_measures.read_trec_run('qrels.run')\n",
    "\n",
    "for model in config:\n",
    "    print(os.path.join(run_path, model+\".run\"))\n",
    "    qrles = ir_measures.read_trec_qrels(qrels_path)\n",
    "    run = ir_measures.read_trec_run(os.path.join(run_path, model+\".run\"))\n",
    "    accuracy = ir_measures.calc_aggregate([nDCG@3, Precision@3, Recall@3], qrles, run)\n",
    "    print(f\"{model}: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5fc5ba0db375a557a527168d68cfbe4f022bc62df7af9d8f86e24130294f8f8e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
