{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python -m spacy download en_core_web_sm\n",
    "# python -m spacy download en\n",
    "\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from spellchecker import SpellChecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "easy to make dessert for christmas\n"
     ]
    }
   ],
   "source": [
    "def stopword_removal(text):\n",
    "    my_file = open(\"stopwords.txt\", \"r\")\n",
    "    stopword_list = my_file.read().split(\"\\n\")\n",
    "    # print(\"stopwords\")\n",
    "    # print(stopword_list)\n",
    "    my_file.close()\n",
    "    \n",
    "    tokens = []\n",
    "    # tokenization\n",
    "    doc = nlp(text, disable=[\"tagger\", \"parser\", \"attribute_ruler\", \"tok2vec\", ])\n",
    "    # stop word removal\n",
    "    for t in doc:\n",
    "        if (not t.is_stop or t.like_num) and not t.is_punct and not t.is_space:\n",
    "            if not str(t) in stopword_list:\n",
    "                tokens.append(t.lemma_.lower())\n",
    "    return tokens\n",
    "\n",
    "def stemming(tokens):\n",
    "    stemmer = SnowballStemmer(language='english')\n",
    "    return [stemmer.stem(token) for token in tokens]\n",
    "\n",
    "def spell_check(tokens):\n",
    "    spell = SpellChecker()\n",
    "    misspelled = spell.unknown(tokens)\n",
    "    words = []\n",
    "    # print(\"misspelled\", misspelled)\n",
    "    for word in tokens:\n",
    "        if word in misspelled:\n",
    "            if not spell.correction(word) is None:\n",
    "                words.append(spell.correction(word))\n",
    "            else:\n",
    "                words.append(word)\n",
    "        else:\n",
    "            words.append(word)\n",
    "    return words\n",
    "\n",
    "def key_words(tokens):\n",
    "    tokens = nlp(\" \".join(tokens))\n",
    "    pos_tag = ['PROPN', 'ADJ', 'NOUN', 'VERB', 'NUM']\n",
    "    return [token.text for token in tokens if token.pos_ in pos_tag]\n",
    "\n",
    "def preprocess_query(query):    \n",
    "    tokens = stopword_removal(query)\n",
    "    # print(\"stop\", tokens)\n",
    "    tokens = spell_check(tokens)\n",
    "    # print(\"spell\", tokens)\n",
    "    tokens = key_words(tokens)\n",
    "    # print(\"key\", tokens)\n",
    "    tokens = stemming(tokens)\n",
    "    # print(\"stem\", tokens)\n",
    "    parsed_query = \" \".join(tokens)\n",
    "    print(query, \" - \", parsed_query)\n",
    "    return parsed_query\n",
    "\n",
    "def stopword_identifier(text):\n",
    "    my_file = open(\"stopwords.txt\", \"r\")\n",
    "    stopword_list = my_file.read().split(\"\\n\")\n",
    "    # print(\"stopwords\")\n",
    "    # print(stopword_list)\n",
    "    my_file.close()\n",
    "    \n",
    "    tokens = []\n",
    "    # tokenization\n",
    "    doc = nlp(text, disable=[\"tagger\", \"parser\", \"attribute_ruler\", \"tok2vec\", ])\n",
    "    # stop word removal\n",
    "    for t in doc:\n",
    "        if (not t.is_stop or t.like_num) and not t.is_punct and not t.is_space:\n",
    "            if not str(t) in stopword_list:\n",
    "                tokens.append(t)\n",
    "    return tokens\n",
    "\n",
    "\n",
    "def shorten_query(query):    \n",
    "    tokens = stopword_removal(query)\n",
    "    non_stop_word = tokens[0]\n",
    "    idx = query.find(non_stop_word)\n",
    "    # print(\"stop\", tokens)\n",
    "    return query[idx:]\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm', disable=['ner'])\n",
    "query = shorten_query(\"I want an easy to make dessert for christmas\")\n",
    "print(query)\n",
    "\n",
    "# text = \"\"\n",
    "# nlp = spacy.load('en_core_web_sm', disable=['ner'])\n",
    "# preprocess_query(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/task-search-quality/env/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how to spatchcock a turkey  -  spatchcock turkey\n",
      "I want an easy to make dessert for christmas  -  easi dessert christma\n",
      "any recommendations for a gluten free appetizer  -  gluten free appet\n",
      "how to make a green goddess salad  -  green goddess salad\n",
      "how to make a classic english trifle  -  classic english trifl\n",
      "I want a scary pumpkin pie  -  scari pumpkin pie\n",
      "ideas for easy to carry tailgate food  -  carri tailgat food\n",
      "I want to make halloween candy  -  halloween candi\n",
      "how to make a gluten free peach crisp  -  gluten free peach\n",
      "healthy zucchini bread  -  healthi zucchini bread\n",
      "recommend some asian street foods  -  asian street food\n",
      "dinners by batali  -  dinner battl\n",
      "traditional japanese soup  -  tradit japanes soup\n",
      "how to make singaporean chicken lunch  -  singapor chicken lunch\n",
      "a romantic dinner  -  romant dinner\n",
      "mexican fiesta recipees  -  mexican fiesta recip\n",
      "a modern icebox cake  -  modern icebox cake\n",
      "food for diwali  -  food diwali\n",
      "i want a fancy eggs recipe  -  fanci egg\n",
      "how to make low fat ice cream  -  low fat ice cream\n",
      "how to prepare napoletana pizza dough  -  napoletana pizza dough\n",
      "make vegetarian tikka masala  -  vegetarian tikka masala\n",
      "i want to make chia pudding recipe low carb  -  chia pud low carb\n",
      "how to make overnight oats  -  overnight oat\n",
      "can i have classic dairy free scones  -  classic dairi free scone\n",
      "how to make spiked eggnog  -  spike eggnog\n",
      "how to prepare spicy oysters  -  spici oyster\n",
      "how to quickly make baby food  -  babi food\n",
      "make lunch meal prep fast  -  lunch meal prep fast\n",
      "make vegetarian eintopf  -  vegetarian eintopf\n",
      "how to make light muffins  -  light muffin\n",
      "make fried halloumi bites  -  fri halloumi bite\n",
      "show me a creamy mushroom stroganoff recipe  -  creami mushroom stroganoff\n",
      "can i have tender cooked pork  -  tender cook pork\n",
      "can i have soup good for the summer  -  soup good summer\n",
      "how to make boiled easter eggs  -  boil easter egg\n",
      "suggestions for road trip food  -  road trip food\n",
      "how to make polish pierogi with cheese  -  polish pierogi chees\n",
      "how can i make one pot ramen  -  one pot ramen\n",
      "how to make a traditional greek dinner  -  tradit greek dinner\n",
      "how to make salty brownies  -  salti browni\n",
      "gingerbread cookies  -  gingerbread cooki\n",
      "how to make a mango and avocado salad  -  mango avocado salad\n",
      "easy granola recipe  -  easi granola\n",
      "chili sin carne  -  chili sin carn\n",
      "savory belgian waffles  -  savori belgian waffl\n",
      "how to make medium rare salmon  -  medium rare salmon\n",
      "a recipe with a whole chicken  -  chicken\n",
      "how to make a refreshing sweet smoothie  -  refresh sweet smoothi\n",
      "a beefy burger  -  beefi burger\n",
      "i would like basic clafoutis with some fresh fruit  -  basic clafouti fresh fruit\n",
      "how to make african meat samosas  -  african meat samosa\n",
      "turkish chicken shish kebab  -  turkish chicken shish kebab\n",
      "how to make old fashioned pie pastry  -  old fashion pie pastri\n",
      "how to bake a multilayer cake  -  bake multiplay cake\n",
      "i want a deep fried chicken recipe  -  fri chicken\n",
      "i would like a fresh and healthy oatmeal bowl  -  healthi oatmeal bowl\n",
      "i want a quick rice salad  -  quick rice salad\n",
      "japanese rice balls  -  japanes rice ball\n",
      "a fresh drink for a sunny day  -  fresh drink sunni day\n",
      "i want some comfort food  -  comfort food\n",
      "suggestions for a summer grill recipe  -  summer grill\n",
      "vegetarian stuffed mushrooms  -  vegetarian stuf mushroom\n",
      "sourdough bread sandwiches  -  sourdough bread sandwich\n",
      "recommendations for a mediterranean potluck  -  mediterranean potluck\n",
      "make a continental breakfast  -  continent breakfast\n",
      "homemade remedy for a cold  -  homemad remedi cold\n",
      "fast and easy picnic foods  -  easi picnic food\n",
      "lunch ideas for fat loss  -  lunch fat loss\n",
      "plant based food recipes  -  plant base food recip\n",
      "jain vegetarianism recipes  -  join vegetarian recip\n",
      "meals pair with wine  -  meal pair wine\n",
      "classic johnny marzetti recipe   -  classic johnni moretti\n",
      "yakamein noodle soup  -  yakamein noodl soup\n",
      "original watermelon agua fresca  -  origin watermelon fresco\n",
      "a rich buttery punjabi dish  -  rich butteri punjabi dish\n",
      "make high protein bibimbap  -  high protein bibimbap\n",
      "protein rich vegetable meal  -  protein rich veget meal\n",
      "original sloppy joe burger  -  origin sloppi joe burger\n",
      "oven baked potatoes  -  bake potato\n",
      "i want a crispy burrito  -  crispi burrito\n",
      "colorful vegatable salad  -  color veget salad\n",
      "slow-cooked fall-off-the-bone ribs  -  cook fall bone rib\n",
      "fluffy cinnamon rolls  -  fluffi cinnamon roll\n",
      "toasted garlic bread pizza  -  toast garlic bread pizza\n",
      "a fast dessert for valentines day  -  fast dessert valentin day\n",
      "thick butternut squash soup  -  thick butternut squash soup\n",
      "an old fashioned beef stew witha  rich broth  -  old fashion beef stew witha rich broth\n",
      "a savory bagel  -  savori bagel\n",
      "fried chinese dumplings  -  fri chines dumpl\n",
      "softly baked cookies  -  bake cooki\n",
      "creamy white mousse  -  creami white mouss\n",
      "a fast icecream recipe  -  fast icecream\n",
      "italian refreshing pasta salad  -  italian refresh pasta salad\n",
      "homemade tomato sauce  -  homemad tomato sauc\n",
      "spicy vegetarian indian curry  -  spici vegetarian indian curri\n",
      "a grilled filling sandwich  -  grill fill sandwich\n",
      "healthy sweet potato french fries  -  healthi sweet potato french fri\n",
      "a well balanced meal  -  balanc meal\n",
      "make chicken soup with homemade broth  -  chicken soup homemad broth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/task-search-quality/env/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving cooking dataset to ../queries/cooking.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/task-search-quality/env/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how to choose a good hirstyle for men  -  choos good hairstyl men\n",
      "how to learn a new language  -  learn new languag\n",
      "how to remove food stains from a carpet  -  remov food stain carpet\n",
      "how to wash a car with less water  -  wash car water\n",
      "how do I decorate an office  -  decor offic\n",
      "help me paint an interior wall  -  paint interior wall\n",
      "how do you remove crown mold from a wall  -  remov crown mold wall\n",
      "how to make homemade toothpaste  -  homemad toothpast\n",
      "how do I clean the fridge  -  clean fridg\n",
      "how can I screw in a nail  -  screw nail\n",
      "how to style curly hair  -  style cur hair\n",
      "how to write a biography for a book  -  write biographi book\n",
      "how to grow apples  -  grow appl\n",
      "how to grow strawberries  -  grow strawberri\n",
      "how to grow cherry tomatoes  -  grow cherri tomato\n",
      "how to grow blueberries  -  grow blueberri\n",
      "how to plant tulips  -  plant tulip\n",
      "how to wash a cutting board  -  wash cut board\n",
      "help me learn how to knit clothes  -  learn knit cloth\n",
      "how to wash a stainless steel pan  -  wash stainless steel pan\n",
      "cut tempered glass  -  cut temper glass\n",
      "put on a bike chain  -  bike chain\n",
      "fix a water heater  -  fix water heater\n",
      "build a simple kite  -  build simpl kite\n",
      "learn how to juggle three balls  -  learn juggl three ball\n",
      "chop an onion like a pro  -  chop onion pro\n",
      "how to hand whistle  -  hand whistl\n",
      "how to change a car tire  -  chang car tire\n",
      "fix a stuck zipper  -  fix stuck zipper\n",
      "paint a metal fence  -  paint metal fenc\n",
      "create an outdoor fireplace  -  creat outdoor fireplac\n",
      "how to remove a tree  -  remov tree\n",
      "paint nails with patterns  -  paint nail pattern\n",
      "make a gravel garden path  -  gravel garden path\n",
      "how to fix a blocked shower drain  -  fix block shower drain\n",
      "how to teach a cat to do tricks  -  teach cat trick\n",
      "how to build a hamster cage  -  build hamster cage\n",
      "how to run  marathon  -  run marathon\n",
      "how to gain musle  -  gain muscl\n",
      "fix a cracked phone screen  -  fix crack phone screen\n",
      "how to plan a christmas party  -  plan christma parti\n",
      "how to solve a rubik's cube  -  solv rubin cube\n",
      "learn a chess opening  -  learn chess open\n",
      "how to replace a window  -  replac window\n",
      "how to iron a suit  -  iron suit\n",
      "how to warm up before a run  -  warm run\n",
      "how to open a champagne bottle  -  open champagn bottl\n",
      "how to install a sprinkler system  -  instal sprinkler system\n",
      "how to change a child's diaper  -  chang child diaper\n",
      "how to make a bubble bath  -  bubbl bath\n",
      "how to remove a permanent marker from a whiteboard  -  remov perman marker whiteboard\n",
      "how to replace a toilet seat  -  replac toilet seat\n",
      "fix a leaking shower  -  fix leak shower\n",
      "how to put up wallpaper  -  wallpap\n",
      "hang a shelf  -  hang shelf\n",
      "sell my paintings on the internet  -  sell paint internet\n",
      "how to make a keychain  -  keychain\n",
      "how to make a bath bomb  -  bath bomb\n",
      "how to make a candles that smell well  -  candl smell\n",
      "how to build a toy for a pet  -  build toy pet\n",
      "how to make napkin designs  -  napkin design\n",
      "how to make a coaster  -  coaster\n",
      "how to draw a birthday card  -  draw birthday card\n",
      "how to set up a tent  -  set tent\n",
      "how to knit mittens  -  knit mitten\n",
      "how to learn to ice skate  -  learn ice skate\n",
      "how to make stickers  -  sticker\n",
      "how to make my own fridge magnets  -  fridg magnet\n",
      "how to organize a kitchen  -  organ kitchen\n",
      "how to make christmas ornaments  -  christma ornament\n",
      "how to build a dog house  -  build dog hous\n",
      "help me clean the oven  -  clean oven\n",
      "how to clean the windows  -  clean window\n",
      "how to pick a lock with paper clips  -  pick lock paper clip\n",
      "how to cut my own hair  -  cut hair\n",
      "how to build a gaming computer  -  build game comput\n",
      "how to write a resume for a job  -  write resum job\n",
      "how to wash a newborn baby  -  wash newborn babi\n",
      "how to train a dog to behave outside  -  train dog behav\n",
      "how to clean garden tools  -  clean garden tool\n",
      "how to make a professional book cover  -  profession book cover\n",
      "how to paint on ceramic  -  paint ceram\n",
      "how to build a snowman  -  build snowman\n",
      "how to make a paper fortune teller  -  paper fortun teller\n",
      "how to fold a paper airplane  -  fold paper airplan\n",
      "how to find my stolen phone  -  find stolen phone\n",
      "how to make finger puppets  -  finger puppet\n",
      "how to repaint wooden furniture  -  repaint wooden furnitur\n",
      "how to catch a fly  -  catch fli\n",
      "how to repair a chipped tile  -  repair chip tile\n",
      "how to make an asian lantern  -  asian lantern\n",
      "how to make paper flowers  -  paper flower\n",
      "how to start a grill  -  start grill\n",
      "how to motivate my child  -  motiv child\n",
      "how to sail a boat  -  sail boat\n",
      "how to replace a door  -  replac door\n",
      "how to fix a door handle  -  fix door handl\n",
      "how to make kitchen curtains  -  kitchen curtain\n",
      "how to grow lemons  -  grow lemon\n",
      "how to grow grapes  -  grow grape\n",
      "Saving diy dataset to ../queries/diy.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/task-search-quality/env/lib/python3.10/site-packages/spacy/pipeline/lemmatizer.py:211: UserWarning: [W108] The rule-based lemmatizer did not find POS annotation for one or more tokens. Check that your pipeline includes components that assign token.pos, typically 'tagger'+'attribute_ruler' or 'morphologizer'.\n",
      "  warnings.warn(Warnings.W108)\n"
     ]
    }
   ],
   "source": [
    "query_types = [\"cooking\", \"diy\"]\n",
    "\n",
    "for q_type in query_types:\n",
    "    \n",
    "\n",
    "    df = pd.read_csv(f\"../queries/{q_type}_raw.csv\")\n",
    "\n",
    "    nlp = spacy.load('en_core_web_sm', disable=['ner'])\n",
    "    df[\"target query\"] = df[\"raw query\"].apply(lambda x: preprocess_query(x))\n",
    "    df[\"short query\"] = df[\"raw query\"].apply(lambda x: shorten_query(x))\n",
    "\n",
    "    ids = [f'query-{i}' for i in range(0, len(df))]\n",
    "    df.insert(0, 'id', ids)\n",
    "\n",
    "    path_to = f\"../queries/{q_type}.csv\"\n",
    "    print(f\"Saving {q_type} dataset to {path_to}\")\n",
    "    df.to_csv(path_to, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5fc5ba0db375a557a527168d68cfbe4f022bc62df7af9d8f86e24130294f8f8e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
